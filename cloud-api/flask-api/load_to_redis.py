"""
Load ALL experiences from PostgreSQL into Redis for ultra-fast lookups.

This script runs ONCE on deployment or when new experiences are added.
After running, ALL API requests use Redis (5-10ms) instead of PostgreSQL (200-400ms).

Result: 40-80x faster queries = <100ms total response time
"""

import os
import sys
import psycopg2
from psycopg2.extras import RealDictCursor
import redis
import pickle
import logging
from datetime import datetime

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Database connection
DB_HOST = os.environ.get('DB_HOST', 'quotrading-db.postgres.database.azure.com')
DB_NAME = os.environ.get('DB_NAME', 'quotrading')
DB_USER = os.environ.get('DB_USER', 'quotradingadmin')
DB_PASSWORD = os.environ.get('DB_PASSWORD', '')

# Redis connection
REDIS_HOST = os.environ.get('REDIS_HOST', 'quotrading-redis.redis.cache.windows.net')
REDIS_PASSWORD = os.environ.get('REDIS_PASSWORD', '')
REDIS_PORT = int(os.environ.get('REDIS_PORT', '6380'))

# Regimes (all possible market conditions)
REGIMES = [
    'NORMAL', 'NORMAL_TRENDING', 'NORMAL_CHOPPY',
    'HIGH_VOL_CHOPPY', 'HIGH_VOL_TRENDING',
    'LOW_VOL_RANGING', 'LOW_VOL_TRENDING'
]

# Sides
SIDES = ['LONG', 'SHORT']


def load_all_to_redis():
    """Load all experiences from PostgreSQL into Redis, organized by symbol/regime/side"""
    
    logging.info("=" * 80)
    logging.info("LOADING ALL EXPERIENCES TO REDIS")
    logging.info(f"Time: {datetime.now()}")
    logging.info("=" * 80)
    
    # Connect to PostgreSQL
    try:
        conn = psycopg2.connect(
            host=DB_HOST,
            database=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD,
            sslmode='require'
        )
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        logging.info("âœ“ Connected to PostgreSQL")
    except Exception as e:
        logging.error(f"âœ— Database connection failed: {e}")
        return False
    
    # Connect to Redis
    try:
        redis_client = redis.StrictRedis(
            host=REDIS_HOST,
            port=REDIS_PORT,
            password=REDIS_PASSWORD,
            ssl=True,
            ssl_cert_reqs=None,
            decode_responses=False
        )
        redis_client.ping()
        logging.info("âœ“ Connected to Redis")
    except Exception as e:
        logging.error(f"âœ— Redis connection failed: {e}")
        return False
    
    total_cached = 0
    total_size_mb = 0
    
    # AUTO-DISCOVER all symbols in database (supports unlimited symbols)
    cursor.execute("SELECT DISTINCT symbol FROM rl_experiences ORDER BY symbol")
    symbols = [row['symbol'] for row in cursor.fetchall()]
    
    if not symbols:
        logging.warning("âš ï¸ No experiences found in database")
        return False
    
    logging.info(f"ðŸ“Š Found {len(symbols)} symbols: {', '.join(symbols)}")
    
    # Load experiences for each symbol/regime/side combination
    for symbol in symbols:
        logging.info(f"\nðŸ“Š Processing symbol: {symbol}")
        
        for regime in REGIMES:
            for side in SIDES:
                
                # Load experiences from PostgreSQL (case-insensitive side matching)
                try:
                    cursor.execute("""
                        SELECT 
                            rsi, vwap_distance, atr, volume_ratio, hour,
                            day_of_week, recent_pnl, streak, side, regime,
                            took_trade, pnl, duration
                        FROM rl_experiences
                        WHERE symbol = %s AND regime = %s AND UPPER(side) = UPPER(%s)
                        ORDER BY created_at DESC
                        LIMIT 10000
                    """, (symbol, regime, side))
                    
                    rows = cursor.fetchall()
                    
                    if not rows:
                        continue  # Skip empty combinations
                    
                    # Convert to RL engine format
                    experiences = []
                    for row in rows:
                        experiences.append({
                            'state': {
                                'rsi': float(row['rsi']),
                                'vwap_distance': float(row['vwap_distance']),
                                'atr': float(row['atr']),
                                'volume_ratio': float(row['volume_ratio']),
                                'hour': int(row['hour']),
                                'day_of_week': int(row['day_of_week']),
                                'recent_pnl': float(row['recent_pnl']),
                                'streak': int(row['streak']),
                                'side': str(row['side']),
                                'regime': str(row['regime'])
                            },
                            'action': {
                                'took_trade': bool(row['took_trade'])
                            },
                            'reward': float(row['pnl']),
                            'duration': float(row['duration'])
                        })
                    
                    # Store in Redis with PERMANENT cache (no TTL)
                    cache_key = f"experiences:{symbol}:{regime}:{side}"
                    pickled_data = pickle.dumps(experiences)
                    data_size_mb = len(pickled_data) / 1024 / 1024
                    
                    redis_client.set(cache_key, pickled_data)
                    
                    total_cached += len(experiences)
                    total_size_mb += data_size_mb
                    
                    logging.info(f"  âœ“ {symbol}/{regime}/{side}: {len(experiences)} experiences ({data_size_mb:.2f} MB)")
                    
                except Exception as e:
                    logging.error(f"  âœ— Error loading {symbol}/{regime}/{side}: {e}")
                    continue
    
    # Close connections
    cursor.close()
    conn.close()
    redis_client.close()
    
    logging.info("\n" + "=" * 80)
    logging.info("REDIS CACHE POPULATED!")
    logging.info(f"Total experiences cached: {total_cached:,}")
    logging.info(f"Total Redis memory used: {total_size_mb:.2f} MB")
    logging.info(f"Time: {datetime.now()}")
    logging.info("=" * 80)
    logging.info("\nâœ… API requests will now use Redis (<10ms) instead of PostgreSQL (200-400ms)")
    logging.info("Expected performance: 50-150ms total response time (40-80x faster queries)")
    logging.info("\nðŸ”„ To refresh cache after new experiences:")
    logging.info("   python load_to_redis.py")
    logging.info("=" * 80)
    
    return True


if __name__ == '__main__':
    success = load_all_to_redis()
    sys.exit(0 if success else 1)
